{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 Ungraded Sections - Part 2: T5 SQuAD Model\n",
    "\n",
    "Welcome to the part 2 of testing the models for this week's assignment. This time we will perform decoding using the T5 SQuAD model. In this notebook we'll perform Question Answering by providing a \"Question\", its \"Context\" and see how well we get the \"Target\" answer. \n",
    "\n",
    "## Colab\n",
    "\n",
    "Since this ungraded lab takes a lot of time to run on coursera, as an alternative we have a colab prepared for you.\n",
    "\n",
    "[T5 SQuAD Model Colab](https://drive.google.com/file/d/1hc7PaXjuuMS0likb0etEHY0ryAzsqAZR/view?usp=sharing)\n",
    "\n",
    "- If you run into a page that looks similar to the one below, with the option `Open with`, this would mean you need to download the `Colaboratory` app. You can do so by `Open with -> Connect more apps -> in the search bar write \"Colaboratory\" -> install`\n",
    "\n",
    "<img src = \"images/colab_help_1.png\"> \n",
    "\n",
    "- After installation it should look like this. Click on `Open with Google Colaboratory`\n",
    "\n",
    "<img src = \"images/colab_help_2.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "- [Overview](#0)\n",
    "- [Part 1: Resuming the assignment (T5 SQuAD Model)](#1)\n",
    "- [Part 2: Fine-tuning on SQuAD](#2)\n",
    "    - [2.1 Loading in the data and preprocessing](#2.1)\n",
    "    - [2.2 Decoding from a fine-tuned model](#2.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='0'></a>\n",
    "### Overview\n",
    "\n",
    "In this notebook you will:\n",
    "* Implement the Bidirectional Encoder Representation from Transformer (BERT) loss. \n",
    "* Use a pretrained version of the model you created in the assignment for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "# Part 1: Getting ready\n",
    "\n",
    "Run the code cells below to import the necessary libraries and to define some functions which will be useful for decoding. The code and the functions are the same as the ones you previsouly ran on the graded assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import t5\n",
    "import numpy as np\n",
    "import trax \n",
    "from trax.supervised import decoding\n",
    "import textwrap \n",
    "\n",
    "wrapper = textwrap.TextWrapper(width=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD, EOS, UNK = 0, 1, 2\n",
    "\n",
    "\n",
    "def detokenize(np_array):\n",
    "    return trax.data.detokenize(\n",
    "        np_array,\n",
    "        vocab_type='sentencepiece',\n",
    "        vocab_file='sentencepiece.model',\n",
    "        vocab_dir='./models/')\n",
    "\n",
    "\n",
    "def tokenize(s):\n",
    "    return next(trax.data.tokenize(\n",
    "        iter([s]),\n",
    "        vocab_type='sentencepiece',\n",
    "        vocab_file='sentencepiece.model',\n",
    "        vocab_dir='./models/'))\n",
    " \n",
    "    \n",
    "vocab_size = trax.data.vocab_size(\n",
    "    vocab_type='sentencepiece',\n",
    "    vocab_file='sentencepiece.model',\n",
    "    vocab_dir='./models/')\n",
    "\n",
    "\n",
    "def get_sentinels(vocab_size, display=False):\n",
    "    sentinels = {}\n",
    "    for i, char in enumerate(reversed(string.ascii_letters), 1):\n",
    "        decoded_text = detokenize([vocab_size - i]) \n",
    "        # Sentinels, ex: <Z> - <a>\n",
    "        sentinels[decoded_text] = f'<{char}>'    \n",
    "        if display:\n",
    "            print(f'The sentinel is <{char}> and the decoded token is:', decoded_text)\n",
    "    return sentinels\n",
    "\n",
    "\n",
    "sentinels = get_sentinels(vocab_size, display=False)    \n",
    "\n",
    "\n",
    "def pretty_decode(encoded_str_list, sentinels=sentinels):\n",
    "    # If already a string, just do the replacements.\n",
    "    if isinstance(encoded_str_list, (str, bytes)):\n",
    "        for token, char in sentinels.items():\n",
    "            encoded_str_list = encoded_str_list.replace(token, char)\n",
    "        return encoded_str_list\n",
    "  \n",
    "    # We need to decode and then prettyfy it.\n",
    "    return pretty_decode(detokenize(encoded_str_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HEoSSKNwgDVA"
   },
   "source": [
    "<a name='2'></a>\n",
    "# Part 2: Fine-tuning on SQuAD\n",
    "\n",
    "Now let's try to fine tune on SQuAD and see what becomes of the model.For this, we need to write a function that will create and process the SQuAD `tf.data.Dataset`. Below is how T5 pre-processes SQuAD dataset as a text2text example. Before we jump in, we will have to first load in the data. \n",
    "\n",
    "<a name='2.1'></a>\n",
    "### 2.1 Loading in the data and preprocessing\n",
    "\n",
    "You first start by loading in the dataset. The text2text example for a SQuAD example looks like:\n",
    "\n",
    "```json\n",
    "{\n",
    "  'inputs': 'question: <question> context: <article>',\n",
    "  'targets': '<answer_0>',\n",
    "}\n",
    "```\n",
    "\n",
    "The squad pre-processing function takes in the dataset and processes it using the sentencePiece vocabulary you have seen above. It generates the features from the vocab and encodes the string features. It takes on question, context, and answer, and returns \"question: Q context: C\" as input and \"A\" as target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RcdR5Dh9UVEw"
   },
   "outputs": [],
   "source": [
    "# Retrieve Question, C, A and return \"question: Q context: C\" as input and \"A\" as target.\n",
    "def squad_preprocess_fn(dataset, mode='train'):\n",
    "    return t5.data.preprocessors.squad(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function map_over_dataset.<locals>.map_without_seeds.<locals>.wrapped_fn.<locals>.<lambda> at 0x7fe48aca0f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function map_over_dataset.<locals>.map_without_seeds.<locals>.wrapped_fn.<locals>.<lambda> at 0x7fe48aca0f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function map_over_dataset.<locals>.map_without_seeds.<locals>.wrapped_fn.<locals>.<lambda> at 0x7fe48aca0f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function _shuffle_data.<locals>.append_targets at 0x7fe48aca25f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function _shuffle_data.<locals>.append_targets at 0x7fe48aca25f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function _shuffle_data.<locals>.append_targets at 0x7fe48aca25f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function map_over_dataset.<locals>.map_without_seeds.<locals>.wrapped_fn.<locals>.<lambda> at 0x7fe48ac2fb00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function map_over_dataset.<locals>.map_without_seeds.<locals>.wrapped_fn.<locals>.<lambda> at 0x7fe48ac2fb00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function map_over_dataset.<locals>.map_without_seeds.<locals>.wrapped_fn.<locals>.<lambda> at 0x7fe48ac2fb00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function _shuffle_data.<locals>.append_targets at 0x7fe48ac2f710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function _shuffle_data.<locals>.append_targets at 0x7fe48ac2f710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function _shuffle_data.<locals>.append_targets at 0x7fe48ac2f710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(b'question: What is the age of US children allowed to work outside of the home ? context: In 2004 , the United States passed an amendment to the Fair Labour Standards Act of 1938 . The amendment allows certain children aged 14 \\xe2\\x80\\x93 18 to work in or outside a business where machinery is used to process wood . The law aims to respect the religious and cultural needs of the Amish community of the United States . The Amish believe that one effective way to educate children is on the job . The new law allows Amish children the ability to work with their families , once they are passed eighth grade in school . ',\n",
       " b'aged 14 \\xe2\\x80\\x93 18')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train generator, this takes about 1 minute\n",
    "train_generator_fn, eval_generator_fn = trax.data.tf_inputs.data_streams(\n",
    "  'squad/v1.1:3.0.0',\n",
    "  data_dir='./data/',\n",
    "  bare_preprocess_fn=squad_preprocess_fn,\n",
    "  input_name='inputs',\n",
    "  target_name='targets'\n",
    ")\n",
    "\n",
    "train_generator = train_generator_fn()\n",
    "next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QGQsExH8xv40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: What can some alleles give rise to ? \n",
      "\n",
      "context:  When multiple different alleles for a gene are present in a species ' s population it is called polymorphic . Most different alleles are functionally equivalent , however some alleles can give rise to different phenotypic traits . A gene ' s most common allele is called the wild type , and rare alleles are called mutants . The genetic variation in relative frequencies of different alleles in a population is due to both natural selection and genetic drift . The wild - type allele is not necessarily the ancestor of less common alleles , nor is it necessarily fitter . \n",
      "\n",
      "target: different phenotypic traits\n"
     ]
    }
   ],
   "source": [
    "#print example from train_generator\n",
    "(inp, out) = next(train_generator)\n",
    "print(inp.decode('utf8').split('context:')[0])\n",
    "print()\n",
    "print('context:', inp.decode('utf8').split('context:')[1])\n",
    "print()\n",
    "print('target:', out.decode('utf8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cC3JaiSMpWma"
   },
   "source": [
    "<a name='2.2'></a>\n",
    "### 2.2 Decoding from a fine-tuned model\n",
    "\n",
    "You will now use an existing model that we trained for you. You will initialize, then load in your model, and then try with your own input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model \n",
    "model = trax.models.Transformer(\n",
    "    d_ff = 4096,\n",
    "    d_model = 1024,\n",
    "    max_len = 2048,\n",
    "    n_heads = 16,\n",
    "    dropout = 0.1,\n",
    "    input_vocab_size = 32000,\n",
    "    n_encoder_layers = 24,\n",
    "    n_decoder_layers = 24,\n",
    "    mode='predict')  # Change to 'eval' for slow decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the model\n",
    "# this will take a minute\n",
    "shape11 = trax.shapes.ShapeDtype((1, 1), dtype=np.int32)\n",
    "model.init_from_file('model_squad.pkl.gz',\n",
    "                     weights_only=True, input_signature=(shape11, shape11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FdGy_pHJGEF6"
   },
   "outputs": [],
   "source": [
    "# create inputs\n",
    "# a simple example \n",
    "# inputs = 'question: She asked him where is john? context: John was at the game'\n",
    "\n",
    "# an extensive example\n",
    "inputs = 'question: What are some of the colours of a rose? context: A rose is a woody perennial flowering plant of the genus Rosa, in the family Rosaceae, or the flower it bears.There are over three hundred species and tens of thousands of cultivars. They form a group of plants that can be erect shrubs, climbing, or trailing, with stems that are often armed with sharp prickles. Flowers vary in size and shape and are usually large and showy, in colours ranging from white through yellows and reds. Most species are native to Asia, with smaller numbers native to Europe, North America, and northwestern Africa. Species, cultivars and hybrids are all widely grown for their beauty and often are fragrant.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing the input so we could feed it for decoding\n",
    "print(tokenize(inputs))\n",
    "test_inputs = tokenize(inputs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to decode.\n",
    "\n",
    "### Note: This will take some time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c_CwYjXHIQOJ"
   },
   "outputs": [],
   "source": [
    "# Temperature is a parameter for sampling.\n",
    "#   # * 0.0: same as argmax, always pick the most probable token\n",
    "#   # * 1.0: sampling from the distribution (can sometimes say random things)\n",
    "#   # * values inbetween can trade off diversity and quality, try it out!\n",
    "output = decoding.autoregressive_sample(model, inputs=np.array(test_inputs)[None, :],\n",
    "                                        temperature=0.0, max_length=5)\n",
    "print(wrapper.fill(pretty_decode(output[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "C4W3-solutions.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
